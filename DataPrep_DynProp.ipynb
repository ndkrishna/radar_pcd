{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8c7abf4-c52b-4080-89e7-e5afa902b94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "from nuscenes.utils.data_classes import Box\n",
    "from nuscenes.utils.data_classes import RadarPointCloud\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(suppress=True, precision=4)  # suppress scientific notation, 4 decimal digits\n",
    "import pandas as pd\n",
    "from nuscenes.can_bus.can_bus_api import NuScenesCanBus\n",
    "from pyquaternion import Quaternion\n",
    "from nuscenes.utils.geometry_utils import view_points\n",
    "import copy\n",
    "import os\n",
    "from scipy.spatial import cKDTree\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cafdb158-d177-4326-bdda-337398e38bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-mini...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "911 instance,\n",
      "12 sensor,\n",
      "120 calibrated_sensor,\n",
      "31206 ego_pose,\n",
      "8 log,\n",
      "10 scene,\n",
      "404 sample,\n",
      "31206 sample_data,\n",
      "18538 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 0.313 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 0.1 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "#Create the nuscene object to read and traverse the data\n",
    "nusc = NuScenes(version='v1.0-mini', dataroot='../data/sets/nuscenes', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee156bfc-bb80-49fd-8623-be04471cb8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCorrespondingCANData(time_stamp):\n",
    "    nusc_can = NuScenesCanBus(dataroot='../data/sets/nuscenes')\n",
    "    can_msgs = nusc_can.get_messages(scene['name'], 'vehicle_monitor')\n",
    "    can_ts = np.array([msg['utime'] for msg in can_msgs])\n",
    "    idx = np.argmin(np.abs(can_ts - time_stamp))\n",
    "    can_msg = can_msgs[idx]\n",
    "    candata = {\n",
    "        'time_stamp' : time_stamp,\n",
    "        'brake': can_msg['brake'],\n",
    "        'brake_switch': can_msg['brake_switch'],\n",
    "        'rear_left_rpm': can_msg['rear_left_rpm'],\n",
    "        'rear_right_rpm' : can_msg['rear_right_rpm'],\n",
    "        'can_utime': can_msg['utime'],\n",
    "        'vehicle_speed': can_msg['vehicle_speed'],\n",
    "        'yaw_rate': can_msg['yaw_rate']\n",
    "        }\n",
    "    return candata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ff1f701-c706-4a9f-acea-e3178b4821b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotation_by_instance(sample, instance_token, nusc):\n",
    "    for ann_token in sample['anns']:\n",
    "        ann = nusc.get('sample_annotation', ann_token)\n",
    "        if ann['instance_token'] == instance_token:\n",
    "            return ann\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65346db7-1523-458c-9f27-03d3d3cfabac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_box_details(ann):\n",
    "    return {\n",
    "        'translation_x': ann['translation'][0],\n",
    "        'translation_y': ann['translation'][1],\n",
    "        'translation_z': ann['translation'][2],\n",
    "        'size_l': ann['size'][0],\n",
    "        'size_w': ann['size'][1],\n",
    "        'size_h': ann['size'][2],\n",
    "        'rotation_w': ann['rotation'][0],\n",
    "        'rotation_x': ann['rotation'][1],\n",
    "        'rotation_y': ann['rotation'][2],\n",
    "        'rotation_z': ann['rotation'][3],\n",
    "        'num_lidar_pts': ann['num_lidar_pts'],\n",
    "        'num_radar_pts': ann['num_radar_pts'],\n",
    "        'category_name': ann['category_name'],\n",
    "        'visibility_token': ann['visibility_token'],\n",
    "        'attribute_tokens': ann['attribute_tokens']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dfd617a-eb4f-424a-962a-3018d48948d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformed_radar_points(radar_data, nusc):\n",
    "    radar_pc = RadarPointCloud.from_file(os.path.join(nusc.dataroot, radar_data['filename']))\n",
    "    \n",
    "    cs_record = nusc.get('calibrated_sensor', radar_data['calibrated_sensor_token'])\n",
    "    pose_record = nusc.get('ego_pose', radar_data['ego_pose_token'])\n",
    "\n",
    "    radar_pc.rotate(Quaternion(cs_record['rotation']).rotation_matrix)\n",
    "    radar_pc.translate(np.array(cs_record['translation']))\n",
    "    radar_pc.rotate(Quaternion(pose_record['rotation']).rotation_matrix)\n",
    "    radar_pc.translate(np.array(pose_record['translation']))\n",
    "\n",
    "    return radar_pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c9bb8ac-641c-451c-a034-d36391e92aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_box_to_sensor_frame(box, sensor_data, nusc):\n",
    "    # Get sensor calibration and ego pose\n",
    "    calib = nusc.get('calibrated_sensor', sensor_data['calibrated_sensor_token'])\n",
    "    pose = nusc.get('ego_pose', sensor_data['ego_pose_token'])\n",
    "\n",
    "    # Global → Ego\n",
    "    translation = np.array(box['translation']) - np.array(pose['translation'])\n",
    "    rotation = Quaternion(pose['rotation']).inverse * Quaternion(box['rotation'])\n",
    "\n",
    "    # Ego → Sensor\n",
    "    translation = Quaternion(calib['rotation']).inverse.rotate(translation - np.array(calib['translation']))\n",
    "    rotation = Quaternion(calib['rotation']).inverse * rotation\n",
    "\n",
    "    return {\n",
    "        'translation_x': translation[0],\n",
    "        'translation_y': translation[1],\n",
    "        'translation_z': translation[2],\n",
    "        'rotation_w': rotation[0],\n",
    "        'rotation_x': rotation[1],\n",
    "        'rotation_y': rotation[2],\n",
    "        'rotation_z': rotation[3],\n",
    "        'size_l': box['size'][0],\n",
    "        'size_w': box['size'][1],\n",
    "        'size_h': box['size'][2]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6b27f1f-3cb1-4bf6-8fa4-cde74c543c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearby_radar_points(box_center, radar_trans_pc, radar_frame_pc, radar_token, threshold=2.5):\n",
    "    radar_trans_xyz = radar_trans_pc.points[:3, :].T\n",
    "    radar_frame_xyz = radar_frame_pc.points[:3, :].T\n",
    "    radar_attrs = radar_frame_pc.points[3:, :].T\n",
    "\n",
    "    tree = cKDTree(radar_trans_xyz)\n",
    "    idxs = tree.query_ball_point(box_center, r=threshold)\n",
    "\n",
    "    # If no points within threshold, fall back to closest\n",
    "    if not idxs:\n",
    "        dist, idx = tree.query(box_center, k=1)\n",
    "        idxs = [idx]\n",
    "\n",
    "    radar_dicts = []\n",
    "    for idx in idxs:\n",
    "        radar_trans_point = radar_trans_xyz[idx]\n",
    "        radar_point = radar_frame_xyz[idx]\n",
    "        radar_attr = radar_attrs[idx]\n",
    "        dist = np.linalg.norm(radar_trans_point - box_center)\n",
    "\n",
    "        radar_dict = {\n",
    "            'radar_token': radar_token,\n",
    "            'radar_x': radar_point[0],\n",
    "            'radar_y': radar_point[1],\n",
    "            'radar_z': radar_point[2],\n",
    "            'radar_trans_x': radar_trans_point[0],\n",
    "            'radar_trans_y': radar_trans_point[1],\n",
    "            'radar_trans_z': radar_trans_point[2],\n",
    "            'dyn_prop': radar_attr[0],\n",
    "            'cluster_id': radar_attr[1],\n",
    "            'rcs': radar_attr[2],\n",
    "            'vx': radar_attr[3],\n",
    "            'vy': radar_attr[4],\n",
    "            'vx_comp': radar_attr[5],\n",
    "            'vy_comp': radar_attr[6],\n",
    "            'is_quality_valid': radar_attr[7],\n",
    "            'ambig_state': radar_attr[8],\n",
    "            'x_rms': radar_attr[9],\n",
    "            'y_rms': radar_attr[10],\n",
    "            'invalid_state': radar_attr[11],\n",
    "            'pdh0': radar_attr[12],\n",
    "            'vx_rms': radar_attr[13],\n",
    "            'vy_rms': radar_attr[14],\n",
    "            'radar_distance': dist\n",
    "        }\n",
    "        radar_dicts.append(radar_dict)\n",
    "\n",
    "    return radar_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae1c0438-589e-4269-9317-f66eaab974ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_cluster_radar_points(box_center, radar_trans_pc, radar_frame_pc, radar_token, threshold=2.5):\n",
    "    radar_trans_xyz = radar_trans_pc.points[:3, :].T\n",
    "    radar_frame_xyz = radar_frame_pc.points[:3, :].T\n",
    "    radar_attrs = radar_frame_pc.points[3:, :].T\n",
    "\n",
    "    tree = cKDTree(radar_trans_xyz)\n",
    "    idxs = tree.query_ball_point(box_center, r=threshold)\n",
    "\n",
    "    # Fallback to closest point if none within threshold\n",
    "    if not idxs:\n",
    "        _, idx = tree.query(box_center, k=1)\n",
    "        idxs = [idx]\n",
    "\n",
    "    # Use the first point (closest) to get its cluster ID\n",
    "    closest_idx = idxs[0]\n",
    "    target_cluster_id = radar_attrs[closest_idx][1]\n",
    "\n",
    "    # Find all points with the same cluster ID\n",
    "    cluster_mask = radar_attrs[:, 1] == target_cluster_id\n",
    "    cluster_indices = np.where(cluster_mask)[0]\n",
    "\n",
    "    radar_dicts = []\n",
    "    for idx in cluster_indices:\n",
    "        radar_trans_point = radar_trans_xyz[idx]\n",
    "        radar_point = radar_frame_xyz[idx]\n",
    "        radar_attr = radar_attrs[idx]\n",
    "        dist = np.linalg.norm(radar_trans_point - box_center)\n",
    "\n",
    "        radar_dict = {\n",
    "            'radar_token': radar_token,\n",
    "            'radar_x': radar_point[0],\n",
    "            'radar_y': radar_point[1],\n",
    "            'radar_z': radar_point[2],\n",
    "            'radar_trans_x': radar_trans_point[0],\n",
    "            'radar_trans_y': radar_trans_point[1],\n",
    "            'radar_trans_z': radar_trans_point[2],\n",
    "            'dyn_prop': radar_attr[0],\n",
    "            'cluster_id': radar_attr[1],\n",
    "            'rcs': radar_attr[2],\n",
    "            'vx': radar_attr[3],\n",
    "            'vy': radar_attr[4],\n",
    "            'vx_comp': radar_attr[5],\n",
    "            'vy_comp': radar_attr[6],\n",
    "            'is_quality_valid': radar_attr[7],\n",
    "            'ambig_state': radar_attr[8],\n",
    "            'x_rms': radar_attr[9],\n",
    "            'y_rms': radar_attr[10],\n",
    "            'invalid_state': radar_attr[11],\n",
    "            'pdh0': radar_attr[12],\n",
    "            'vx_rms': radar_attr[13],\n",
    "            'vy_rms': radar_attr[14],\n",
    "            'radar_distance': dist\n",
    "        }\n",
    "        radar_dicts.append(radar_dict)\n",
    "\n",
    "    return radar_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2f9b36a-f423-4d33-a15e-6c99cfc4ebe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from pyquaternion import Quaternion\n",
    "\n",
    "def is_annotation_visible_in_front_camera(nusc, ann_token, sample):\n",
    "    \"\"\"\n",
    "    Checks if the annotation is visible in the CAM_FRONT image.\n",
    "    \n",
    "    Parameters:\n",
    "        nusc: NuScenes instance\n",
    "        ann_token: Token of the annotation to check\n",
    "        sample: Sample dictionary containing 'data' field\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if annotation is visible in CAM_FRONT image, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get camera data\n",
    "        cam_token = sample['data']['CAM_FRONT']\n",
    "        cam_data = nusc.get('sample_data', cam_token)\n",
    "        cam_cs = nusc.get('calibrated_sensor', cam_data['calibrated_sensor_token'])\n",
    "        cam_pose = nusc.get('ego_pose', cam_data['ego_pose_token'])\n",
    "        cam_intrinsic = np.array(cam_cs['camera_intrinsic'])\n",
    "\n",
    "        # Get box and transform to camera frame\n",
    "        box = nusc.get_box(ann_token)\n",
    "        box.translate(-np.array(cam_pose['translation']))\n",
    "        box.rotate(Quaternion(cam_pose['rotation']).inverse)\n",
    "        box.translate(-np.array(cam_cs['translation']))\n",
    "        box.rotate(Quaternion(cam_cs['rotation']).inverse)\n",
    "\n",
    "        # Project box corners\n",
    "        corners = box.corners()\n",
    "        corners_cam = cam_intrinsic @ corners\n",
    "        depths = corners_cam[2, :]\n",
    "\n",
    "        # Check if behind camera\n",
    "        if np.any(depths <= 0):\n",
    "            return False\n",
    "\n",
    "        # Project to 2D\n",
    "        corners_2d = corners_cam[:2, :] / depths\n",
    "        corners_2d = corners_2d.T.astype(np.int32)\n",
    "\n",
    "        # Load image and check bounds\n",
    "        image_path = os.path.join(nusc.dataroot, cam_data['filename'])\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            return False\n",
    "\n",
    "        H, W = image.shape[:2]\n",
    "        if np.any(corners_2d[:, 0] < 0) or np.any(corners_2d[:, 0] >= W) or \\\n",
    "           np.any(corners_2d[:, 1] < 0) or np.any(corners_2d[:, 1] >= H):\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Visibility check failed: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa88314b-36ae-4c25-84d8-1f5ff496a4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for scene in nusc.scene:\n",
    "    scene_token = scene['token']\n",
    "    scene_name = scene['name']\n",
    "    \n",
    "    sample_token = scene['first_sample_token']\n",
    "    \n",
    "    while sample_token:\n",
    "        sample = nusc.get('sample', sample_token)\n",
    "        next_token = sample['next']\n",
    "        \n",
    "        cam_token = sample['data']['CAM_FRONT']\n",
    "        cam_data = nusc.get('sample_data', cam_token)\n",
    "        camera_pose = nusc.get('ego_pose', cam_data['ego_pose_token'])\n",
    "\n",
    "        radar_token = sample['data']['RADAR_FRONT']\n",
    "        radar_data = nusc.get('sample_data', radar_token)\n",
    "\n",
    "        radar_pc = RadarPointCloud.from_file(os.path.join(nusc.dataroot, radar_data['filename']))\n",
    "        radar_trans_pc = get_transformed_radar_points(radar_data, nusc)\n",
    "\n",
    "        can_msg = getCorrespondingCANData(radar_data['timestamp'])\n",
    "\n",
    "        for ann_token in sample['anns']:\n",
    "            ann = nusc.get('sample_annotation', ann_token)\n",
    "\n",
    "            if not is_annotation_visible_in_front_camera(nusc, ann_token, sample):\n",
    "                continue\n",
    "\n",
    "            box_radar = transform_box_to_sensor_frame(ann, radar_data, nusc)\n",
    "\n",
    "            #Tried with nearby points with better results. Even the RADAR is doing approximation with cluster ID\n",
    "            radar_rows = get_nearby_radar_points(ann['translation'], radar_trans_pc, radar_pc, radar_token)\n",
    "            #This function gets all the points in the same cluster. This result in the dyn_model2 was not as good as closest points\n",
    "            #radar_rows = get_closest_cluster_radar_points(ann['translation'], radar_trans_pc, radar_pc, radar_token)\n",
    "\n",
    "            for radar_row in radar_rows:\n",
    "                if next_token:\n",
    "                    row = {\n",
    "                        'scene_token': scene_token,\n",
    "                        'scene_name': scene_name,\n",
    "                        'sample_token': sample_token,\n",
    "                        'next_sample_token': next_token,\n",
    "                        'instance_token': ann['instance_token'],\n",
    "                        'camera_pose_x': camera_pose['translation'][0],\n",
    "                        'camera_pose_y': camera_pose['translation'][1],\n",
    "                        'camera_pose_z': camera_pose['translation'][2],\n",
    "                    }\n",
    "    \n",
    "                    row.update({f'box_{k}': v for k, v in extract_box_details(ann).items()})\n",
    "                    row.update({f'box_rad_{k}': v for k, v in box_radar.items()})\n",
    "                    row.update({f'radar_{k}': v for k, v in radar_row.items()})\n",
    "                    row.update({f'can_{k}': v for k, v in can_msg.items()})\n",
    "    \n",
    "                    rows.append(row)\n",
    "\n",
    "        sample_token = next_token  # Move to next sample\n",
    "\n",
    "df_single_instance = pd.DataFrame(rows)\n",
    "df_single_instance = df_single_instance.drop(['box_num_lidar_pts', 'box_num_radar_pts', 'box_visibility_token', 'box_attribute_tokens'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b675caa-7e53-41ed-b746-0c322a828b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6250, 60)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_single_instance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36357ee4-5006-4103-9cb1-a9ef05e1196b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_single_instance.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22ef5efe-5b3a-41fc-a474-56ee0151001e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6250, 60)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_single_instance = df_single_instance.drop_duplicates()\n",
    "df_single_instance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96dcc8aa-ff40-4f8e-8eeb-cd7a11ae889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_single_instance.to_excel('Box_PCD_Association.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adb5480f-4bb7-4679-a178-db5969ea451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a renamed copy of the original DataFrame to act as \"B\"\n",
    "df_a = df_single_instance.copy()\n",
    "df_b = df_single_instance.copy()\n",
    "\n",
    "df_a = df_a.add_prefix(\"a_\")  # So B.sample_token becomes next_sample_token\n",
    "df_b = df_b.add_prefix(\"b_\")  # So B.sample_token becomes next_sample_token\n",
    "\n",
    "# Perform the join: A.next_sample_token == B.sample_token AND A.instance_token == B.instance_token\n",
    "df_merged = pd.merge(\n",
    "    df_a,         # A\n",
    "    df_b,         # B\n",
    "    left_on=[\"a_next_sample_token\", \"a_instance_token\"],\n",
    "    right_on=[\"b_sample_token\", \"b_instance_token\"],\n",
    "    how=\"inner\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fed9105-14b9-4d2a-be56-8ee12020db90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9482, 120)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5704c50-86c7-4a3a-a38b-639396596c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9482, 120)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = df_merged.drop_duplicates()\n",
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4e8b1ba-3104-4882-bf38-ec25668516d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_excel('BoxAB_PCD_Association.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (radarviz)",
   "language": "python",
   "name": "radarviz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
