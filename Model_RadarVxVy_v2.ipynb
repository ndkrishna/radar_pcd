{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "735bc3f3-4bd8-4c4a-929e-b56e418bc67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pyquaternion import Quaternion\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62e5abc3-fdcd-418e-a4d5-965ca085188c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Excel file\n",
    "df_ref = pd.read_excel('Filtered_PCD_Annotations_AB.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1310bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the object perspective \n",
    "def get_object_perspective(cam_pose_x, cam_pose_y, box_x, box_y, box_z, box_rotation_w, box_rotation_z):\n",
    "    \"\"\"\n",
    "    Determines the perspective of an object relative to the camera.\n",
    "\n",
    "    Parameters:\n",
    "    - box_center: np.array([x, y, z]) ‚Üí center of the box in world coordinates\n",
    "    - orientation_quat: Quaternion(w, 0, 0, z) ‚Üí rotation around Z-axis only\n",
    "    - cam_position: np.array([x, y, z]) ‚Üí camera position in world coordinates\n",
    "    - threshold: angle threshold in radians for classification\n",
    "\n",
    "    Returns:\n",
    "    - One of: 'toward', 'away', 'left', 'right'\n",
    "    \"\"\"\n",
    "    threshold=np.pi / 4\n",
    "\n",
    "    # Camera position in global coordinates\n",
    "    cam_position = np.array([cam_pose_x, cam_pose_y, 0])  # shape: (3,)\n",
    "\n",
    "    orientation_quat = Quaternion(\n",
    "        box_rotation_w,\n",
    "        0.0, 0.0,\n",
    "        box_rotation_z\n",
    "    )\n",
    "    \n",
    "    # Compute forward direction of the box (local +X axis rotated by orientation)\n",
    "    forward_vector = orientation_quat.rotate(np.array([1, 0, 0]))  # shape: (3,)\n",
    "\n",
    "    # Vector from box to camera\n",
    "    box_center = [box_x, box_y, box_z]\n",
    "    to_camera = cam_position - box_center\n",
    "    to_camera = to_camera / np.linalg.norm(to_camera)\n",
    "\n",
    "    # Compute angle between forward direction and camera vector\n",
    "    dot = np.dot(forward_vector[:2], to_camera[:2])  # only XY plane\n",
    "    angle = np.arccos(np.clip(dot, -1.0, 1.0))  # radians\n",
    "\n",
    "    # Pad vectors to 3D by adding a zero Z-component\n",
    "    forward_xy = np.array([forward_vector[0], forward_vector[1], 0])\n",
    "    to_camera_xy = np.array([to_camera[0], to_camera[1], 0])\n",
    "    \n",
    "    # Compute cross product and extract Z-component\n",
    "    cross_z = np.cross(forward_xy, to_camera_xy)[2]\n",
    "\n",
    "\n",
    "    # Classify based on angle and cross product\n",
    "    if angle < threshold:\n",
    "        return 0 #'toward'\n",
    "    elif angle > (np.pi - threshold):\n",
    "        return 1 #'away'\n",
    "    elif cross_z > 0:\n",
    "        return 2 #'left'\n",
    "    else:\n",
    "        return 3 #'right'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a053e182-78be-4fb3-81de-7e4eec8366a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5376, 62)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Excel file\n",
    "\n",
    "df = df_ref.copy()\n",
    "\n",
    "selected_columns = [\n",
    "    'a_camera_pose_x', 'a_camera_pose_y', 'a_camera_pose_z', \n",
    "    'b_camera_pose_x', 'b_camera_pose_y', 'b_camera_pose_z', \n",
    "    'a_center_x', 'a_center_y', 'a_center_z', \n",
    "    'b_center_x', 'b_center_y', 'b_center_z', \n",
    "    'a_length', 'a_width', 'a_height', \n",
    "    'b_length', 'b_width', 'b_height', \n",
    "    'a_rotation_w', 'a_rotation_x', 'a_rotation_y', 'a_rotation_z', \n",
    "    'b_rotation_w', 'b_rotation_x', 'b_rotation_y', 'b_rotation_z', \n",
    "    'a_yaw', \n",
    "    'b_yaw',\n",
    "    'a_category',\n",
    "    'b_category', \n",
    "    'a_brake', 'a_brake_switch', 'a_rear_left_rpm', 'a_rear_right_rpm', 'a_vehicle_speed', 'a_yaw_rate',\n",
    "    'b_brake', 'b_brake_switch', 'b_rear_left_rpm', 'b_rear_right_rpm', 'b_vehicle_speed', 'b_yaw_rate',\n",
    "    'a_distance', \n",
    "    'b_distance', \n",
    "    'a_vx', 'a_vy',             \n",
    "    'b_vx', 'b_vy']\n",
    "    \n",
    "\n",
    "\n",
    "df = df[selected_columns]\n",
    "\n",
    "\n",
    "# Encode box1_category_name\n",
    "le_category = LabelEncoder()\n",
    "df['a_category_encoded'] = le_category.fit_transform(df['a_category'])\n",
    "\n",
    "\n",
    "df['a_box_perspective'] = df.apply(\n",
    "    lambda row: get_object_perspective(\n",
    "        row['a_camera_pose_x'],\n",
    "        row['a_camera_pose_y'],\n",
    "        row['a_center_x'],\n",
    "        row['a_center_y'],\n",
    "        row['a_center_z'],\n",
    "        row['a_rotation_w'],\n",
    "        row['a_rotation_z']\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_cleaned_data = df.copy()\n",
    "\n",
    "df_cleaned_data = df_cleaned_data.drop_duplicates()\n",
    "\n",
    "# Translation deltas\n",
    "df_cleaned_data['delta_center_x'] = df_cleaned_data['b_center_x'] - df_cleaned_data['a_center_x']\n",
    "df_cleaned_data['delta_center_y'] = df_cleaned_data['b_center_y'] - df_cleaned_data['a_center_y']\n",
    "df_cleaned_data['delta_center_z'] = df_cleaned_data['b_center_z'] - df_cleaned_data['a_center_z']\n",
    "\n",
    "df_cleaned_data['delta_length'] = df_cleaned_data['b_length'] - df_cleaned_data['a_length']\n",
    "df_cleaned_data['delta_width'] = df_cleaned_data['b_width'] - df_cleaned_data['a_width']\n",
    "df_cleaned_data['delta_height'] = df_cleaned_data['b_height'] - df_cleaned_data['a_height']\n",
    "\n",
    "\n",
    "df_cleaned_data['delta_vehicle_speed'] = df_cleaned_data['b_vehicle_speed'] - df_cleaned_data['a_vehicle_speed']\n",
    "\n",
    "def compute_delta_quaternion(row):\n",
    "    q1 = Quaternion([row['a_rotation_w'], 0.0, 0.0, row['a_rotation_z']])\n",
    "    q2 = Quaternion([row['b_rotation_w'], 0.0, 0.0, row['b_rotation_z']])\n",
    "    delta_q = q2 * q1.inverse\n",
    "    return pd.Series({'delta_rotation_w': delta_q.w, 'delta_rotation_x': delta_q.x, 'delta_rotation_y': delta_q.y,'delta_rotation_z': delta_q.z})\n",
    "\n",
    "df_quat_delta = df_cleaned_data.apply(compute_delta_quaternion, axis=1)\n",
    "df_cleaned_data = pd.concat([df_cleaned_data, df_quat_delta], axis=1)\n",
    "\n",
    "# Remove columns with only one unique value\n",
    "df_cleaned_data = df_cleaned_data.loc[:, df_cleaned_data.nunique() > 1]\n",
    "\n",
    "\n",
    "df_cleaned_data['a_category_encoded'] = df_cleaned_data['a_category_encoded'].astype('category')\n",
    "\n",
    "df_cleaned_data = df_cleaned_data.drop(['a_category', 'b_category'], axis=1)\n",
    "\n",
    "# Select numeric features\n",
    "non_numeric_cols = df_cleaned_data.select_dtypes(exclude='number').columns.tolist()\n",
    "df_cleaned_data = pd.get_dummies(df_cleaned_data, columns=non_numeric_cols, drop_first=True)\n",
    "\n",
    "df_cleaned_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6d6a916",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select numeric features\n",
    "numeric_df = df_cleaned_data.select_dtypes(include='number')\n",
    "\n",
    "numeric_df = numeric_df.drop(['a_vx', 'a_vy', 'b_vx', 'b_vy'], axis=1)  \n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(numeric_df)\n",
    "\n",
    "pca = PCA(n_components=min(10, X_scaled.shape[1]))  # You can adjust n_components\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "y1 = df_cleaned_data['a_vx']\n",
    "y2 = df_cleaned_data['a_vy']\n",
    "\n",
    "\n",
    "X_train, X_test, y1_train, y1_test, y2_train, y2_test = train_test_split(\n",
    "    X_pca, y1, y2, test_size=0.2, random_state=43\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8439e399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['a_camera_pose_x', 'a_camera_pose_y', 'b_camera_pose_x',\n",
       "       'b_camera_pose_y', 'a_center_x', 'a_center_y', 'a_center_z',\n",
       "       'b_center_x', 'b_center_y', 'b_center_z', 'a_length', 'a_width',\n",
       "       'a_height', 'b_length', 'b_width', 'b_height', 'a_rotation_w',\n",
       "       'a_rotation_z', 'b_rotation_w', 'b_rotation_z', 'a_yaw', 'b_yaw',\n",
       "       'a_brake', 'a_brake_switch', 'a_rear_left_rpm', 'a_rear_right_rpm',\n",
       "       'a_vehicle_speed', 'a_yaw_rate', 'b_brake', 'b_brake_switch',\n",
       "       'b_rear_left_rpm', 'b_rear_right_rpm', 'b_vehicle_speed', 'b_yaw_rate',\n",
       "       'a_distance', 'b_distance', 'a_box_perspective', 'delta_center_x',\n",
       "       'delta_center_y', 'delta_center_z', 'delta_vehicle_speed',\n",
       "       'delta_rotation_w', 'delta_rotation_z'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0d00702-6daf-4a5b-b0a1-0dcbe3184a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'GradientBoosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    'SVR': SVR()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "829b4e2d-2870-4834-a3bf-cac3ae927111",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y1_train)\n",
    "    y1_pred = model.predict(X_test)\n",
    "    results[name] = {\n",
    "        'RMSE': np.sqrt(mean_squared_error(y1_test, y1_pred)),\n",
    "        'MAE': mean_absolute_error(y1_test, y1_pred),\n",
    "        'R2': r2_score(y1_test, y1_pred)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02368bc8-f26e-4cfc-86f3-9476f0c0d285",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dilip\\anaconda3\\envs\\radarviz\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "nn_model = Sequential([\n",
    "    Dense(16, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "nn_model.compile(optimizer=Adam(learning_rate=0.01), loss='mse', metrics=['mae'])\n",
    "\n",
    "nn_model.fit(X_train, y1_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "y1_pred_nn = nn_model.predict(X_test).flatten()\n",
    "results['NeuralNet'] = {\n",
    "    'RMSE': np.sqrt(mean_squared_error(y1_test, y1_pred_nn)),\n",
    "    'MAE': mean_absolute_error(y1_test, y1_pred_nn),\n",
    "    'R2': r2_score(y1_test, y1_pred_nn)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa18f0e6-f187-4876-a5bd-6dcd011c3288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      RMSE       MAE        R2\n",
      "LinearRegression  2.903320  1.846974  0.457143\n",
      "RandomForest      1.140691  0.493589  0.916202\n",
      "GradientBoosting  1.778115  1.036279  0.796382\n",
      "SVR               1.843021  0.876464  0.781246\n",
      "NeuralNet         1.351599  0.809062  0.882350\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48684a2b-ed6e-4618-9667-7f54615f9142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Random Forest Performance:\n",
      "RMSE: 1.1057\n",
      "MAE: 0.4852\n",
      "R2: 0.9213\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Step 1: Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_train, y1_train)\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Step 2: Predict and evaluate\n",
    "y1_pred_rf = best_rf.predict(X_test)\n",
    "results['RandomForest_Tuned'] = {\n",
    "    'RMSE': np.sqrt(mean_squared_error(y1_test, y1_pred_rf)),\n",
    "    'MAE': mean_absolute_error(y1_test, y1_pred_rf),\n",
    "    'R2': r2_score(y1_test, y1_pred_rf)\n",
    "}\n",
    "\n",
    "# Print results\n",
    "print(\"üîç Random Forest Performance:\")\n",
    "for metric, value in results['RandomForest_Tuned'].items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Step 3: Residual analysis\n",
    "#residuals = y1_test - y1_pred_rf\n",
    "#plt.figure(figsize=(6, 4))\n",
    "#plt.hist(residuals, bins=50, color='teal', alpha=0.7)\n",
    "#plt.title(\"Residuals Distribution (Random Forest)\")\n",
    "#plt.xlabel(\"Error\")\n",
    "#plt.ylabel(\"Frequency\")\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38400b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'GradientBoosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    'SVR': SVR()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcd3c98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y2_train)\n",
    "    y2_pred = model.predict(X_test)\n",
    "    results[name] = {\n",
    "        'RMSE': np.sqrt(mean_squared_error(y2_test, y2_pred)),\n",
    "        'MAE': mean_absolute_error(y2_test, y2_pred),\n",
    "        'R2': r2_score(y2_test, y2_pred)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b71e46a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dilip\\anaconda3\\envs\\radarviz\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "nn_model = Sequential([\n",
    "    Dense(16, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "nn_model.compile(optimizer=Adam(learning_rate=0.01), loss='mse', metrics=['mae'])\n",
    "\n",
    "nn_model.fit(X_train, y2_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "y2_pred_nn = nn_model.predict(X_test).flatten()\n",
    "results['NeuralNet'] = {\n",
    "    'RMSE': np.sqrt(mean_squared_error(y2_test, y2_pred_nn)),\n",
    "    'MAE': mean_absolute_error(y2_test, y2_pred_nn),\n",
    "    'R2': r2_score(y2_test, y2_pred_nn)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee251121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      RMSE       MAE        R2\n",
      "LinearRegression  1.268204  0.913297  0.733753\n",
      "RandomForest      0.380021  0.157075  0.976093\n",
      "GradientBoosting  0.620783  0.365812  0.936205\n",
      "SVR               0.732179  0.345551  0.911255\n",
      "NeuralNet         0.511090  0.283217  0.956758\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ea1e20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Random Forest Performance:\n",
      "RMSE: 0.3704\n",
      "MAE: 0.1557\n",
      "R2: 0.9773\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Step 1: Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_train, y2_train)\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Step 2: Predict and evaluate\n",
    "y2_pred_rf = best_rf.predict(X_test)\n",
    "results['RandomForest_Tuned'] = {\n",
    "    'RMSE': np.sqrt(mean_squared_error(y2_test, y2_pred_rf)),\n",
    "    'MAE': mean_absolute_error(y2_test, y2_pred_rf),\n",
    "    'R2': r2_score(y2_test, y2_pred_rf)\n",
    "}\n",
    "\n",
    "# Print results\n",
    "print(\"üîç Random Forest Performance:\")\n",
    "for metric, value in results['RandomForest_Tuned'].items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Step 3: Residual analysis\n",
    "#residuals = y1_test - y1_pred_rf\n",
    "#plt.figure(figsize=(6, 4))\n",
    "#plt.hist(residuals, bins=50, color='teal', alpha=0.7)\n",
    "#plt.title(\"Residuals Distribution (Random Forest)\")\n",
    "#plt.xlabel(\"Error\")\n",
    "#plt.ylabel(\"Frequency\")\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (radarviz)",
   "language": "python",
   "name": "radarviz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
